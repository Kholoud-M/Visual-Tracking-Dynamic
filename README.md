# Visual Tracking Dynamic
Human visual attention has been widely studied using eye-tracking to monitor where a subject
looks and when. Decisions about where to look at any given instant appear to be determined by a
combination of multiple, constantly changing internal and external factors including top-down task
demands, such as searching for a specific object (Torralba, Oliva, Castelhano, & Henderson, 2006;
Yarbus, 1967), bottom-up image features, such as colors/contrast (L Itti, Koch, & Niebur, 1998), and
familiarity with the objects in a scene (Najemnik & Geisler, 2005). Computational descriptions of visual 
attention have quantified each of these phenomena (Laurent Itti & Koch, 2001) and, in many cases, 
it is possible to accurately predict where a person will look in a scene and when (Judd, Durand, & Torralba, 2012).
Although these models have had a great deal of success, the majority of work in this area has focused on describing
visual attention to simplified stimuli: static images or videos with still cameras. In everyday life, on the other hand,
our bodies are constantly moving and we direct our visual attention in the presence of large, global translations and 
rotations of the entire visual scene (Koenderink, 1986). 

# Stimuli
280 natural movies taken from 4 documentaries (Home, Earth, Salt-fat-acid-heat, Urbanized)
And the middle frame from each clip is played as a static non moving image for the same amount of time. 
Stored in Stimuli_Sep2019



